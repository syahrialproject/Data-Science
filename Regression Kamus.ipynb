{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decission Tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor(random_state = 0)\n",
    "regressor.fit(X, y)\n",
    "regressor.predict([[6.6]])\n",
    "\n",
    "#Multiple Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "#LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "#Polynomial Regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg = PolynomialFeatures(degree = 4)\n",
    "X_poly = poly_reg.fit_transform(X)\n",
    "lin_reg_2 = LinearRegression()\n",
    "lin_reg_2.fit(X_poly, y)\n",
    "lin_reg_2.predict(poly_reg.fit_transform([[6.5]]))\n",
    "\n",
    "#SVR\n",
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel = 'rbf')\n",
    "regressor.fit(X, y)\n",
    "\n",
    "\n",
    "#Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=10)\n",
    "\n",
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "for i in Categorical:\n",
    "    df[i] = LE.fit_transform(df[i])\n",
    "    \n",
    "#One hot encode\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "# logarithmic all data numeric\n",
    "for i in numerical:\n",
    "    df[i] = np.log(df[i]+1)\n",
    "    \n",
    "\n",
    "#PLOT Correlation\n",
    "corr = data.corr()\n",
    "plt.figure(figsize=(20,15))\n",
    "sns.heatmap(corr, annot=True, annot_kws={'size':9})\n",
    "plt.title('Correlation Clean Data')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Feature Selection\n",
    "for col in feat_corr['mytsel_lapse'].index[1:]:\n",
    "    # Pick desired cutoff for dropping features. In absolute-value terms.\n",
    "    if np.absolute(feat_corr.loc['mytsel_lapse',col]) < 0.1:\n",
    "        # Drop the feature if correlation is below cutoff\n",
    "        data.drop(columns=col, inplace=True)\n",
    "print('-'*40)\n",
    "print('\\nData shape after feature selection:', data.shape)\n",
    "print('\\nCounts of lapse VS non-lapse in new data:')\n",
    "print(data['mytsel_lapse'].value_counts())\n",
    "print('-'*40)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
